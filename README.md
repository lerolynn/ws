# Weakly Supervised Semantic Segmentation

This repository runs the full Weakly Supervised Semantic Segmentaiton pipeline following the method of [IRNet](https://github.com/jiwoon-ahn/irn)

## Installation

This repository is tested on Ubuntu 18.04, using Python 3.7 and Pytorch >= 1.11 Other environment variables are as specified in the `environment.yml` file.

_Note: Pytorch environment should be suitable to your CUDA version. This repository was tested on Pytorch versions 1.11.0 and 1.12.0 for the Nvidia RTX 2080Ti and 3090 GPUs respectively._

---

### Quick Setup

To setup the environment variables and install the required datasets, run `setup.sh` in the root directory of the repository.

```console
.source setup.sh
```

The setup script is configured to set up the Anaconda environment, download the PASCAL VOC2012, the MS COCO2014 datasets and the pretrained segmentation weights

---

#### Setup Steps:

1. Install and setup the Conda environment `wsss`
2. The datasets are downloaded and moved to the folders as specified in the directory hierarchy [here](./data/README.md). (Pseudo masks will be generated by subsequent steps) More information on the datasets is located in the [README](./data/README.md) of the data folder.

   * Pascal VOC2012 is downloaded from the official [Pascal VOC website](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/#devkit)

3. Download weights used for the segmentation model. Weights are pretrained on the ImageNet dataset for fair comparison, and are provided by the authors of [RIB](https://github.com/jbeomlee93/RIB).

---

### CGNet

Download Pretrained Weights
* ImageNet-pretrained weights for resnet38d are from [[resnet_38d.params]](https://github.com/itijyou/ademxapp).
You need to place the weights as ./pretrained/resnet_38d.params.
* PASCAL-pretrained weights for resnet38d are from [[od_cam.pth]](https://github.com/jiwoon-ahn/psa).
You need to place the weights as ./pretrained/od_cam.pth.

#### Run and generate CAMs from CGNet

```
python train.py --name cgnet_cam --model model_cse
python infer.py --name cgnet_cam --model model_cse --load_epo 5 --vis --dict --crf --alphas 6 10 24
```

Convert CGNet CAMs to format used by IRN and AMN. Move CAMs generated from CGNet to `cgnet/input/` in `pseudo_mask` directory.

```
cd pseudo_mask
python ../utils/cgnet_to_cam.py
```
Output will be in `cgnet/output/` in `pseudo_mask` directory.

#### Run AMN using CAMs from CGNet
```
cd AMN
bash scripts/generate_pseudo_mask.sh
```

### Segmentation

Semantic Segmentation is run in the `segmentation` directory. From the root directory:

```console
cd segmentation
```

#### VOC2012 dataset

Train DeeplabV2 on psuedo-labels generated from IRN:
```console
python main.py train --config-path configs/voc12.yaml
```

Evaluate performance on validation set:
```console
python main.py test --config-path configs/voc12.yaml --model-path output/voc12/models/train/checkpoint_final.pth
```

Evaluate with CRF post-processing:
```console
python main.py crf --config-path configs/voc12.yaml
```

## Acknowledgment

Significant portions of the code from this repository was borrowed from [IRN](https://github.com/jiwoon-ahn/irn) and [deeplab-pytorch](https://github.com/kazuto1011/deeplab-pytorch). Thank you [Jiwoon Ahn](https://github.com/jiwoon-ahn/irn) and [
Kazuto Nakashima](https://github.com/kazuto1011).

CGNet was borrowed from [OC-CSE](https://github.com/KAIST-vilab/OC-CSE), while AMN was borrowed from  [AMN](https://github.com/gaviotas/AMN).